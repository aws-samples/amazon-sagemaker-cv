{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download COCO dataset and weight, convert data to TFRecords and upload to S3\n",
    "# Guide for preparing data and weight https://github.com/HerringForks/DeepLearningExamples/tree/master/TensorFlow2/Segmentation/MaskRCNN#quick-start-guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.inputs import FileSystemInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the default region\n",
    "region = \"us-west-2\"\n",
    "os.environ['AWS_DEFAULT_REGION'] = region\n",
    "role = get_execution_role()\n",
    "\n",
    "user_id = \"johndoe\"\n",
    "time_str = datetime.now().strftime(\"%H-%M-%S\")\n",
    "\n",
    "instance_type = \"ml.p4d.24xlarge\"\n",
    "instance_count = 1\n",
    "\n",
    "# single node training with total batch size of 64\n",
    "# parameters are only for illustration purpose, user may need to tune to fit their workload\n",
    "config_file = \"configs/mrcnn_bs64.yaml\"\n",
    "hyperparameters = {\"config\": config_file}\n",
    "\n",
    "# enable SMDDP\n",
    "distribution = {\"smdistributed\": {\"dataparallel\": {\"enabled\": True}}}\n",
    "\n",
    "job_name = f'{user_id}-maskrcnn-keras-p4d-{instance_count}-{time_str}'\n",
    "\n",
    "source_dir = \".\"\n",
    "entry_point = \"train_keras.py\"\n",
    "\n",
    "# shared SMDDP Keras docker image\n",
    "docker_image = \"<image_uri>\"\n",
    "\n",
    "# all files under the directory will be mounted under /opt/ml/input/data/train/, make sure it aligns with config file\n",
    "s3_data_dir = \"<s3-path-to-dataset-directory>\"\n",
    "channels = {'train': s3_data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "            entry_point=entry_point,\n",
    "            role=role,\n",
    "            image_uri=docker_image,\n",
    "            source_dir=source_dir,\n",
    "            instance_count=instance_count,\n",
    "            instance_type=instance_type,\n",
    "            hyperparameters=hyperparameters,\n",
    "            disable_profiler=True,\n",
    "            debugger_hook_config=False,\n",
    "            distribution=distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(inputs=channels, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
