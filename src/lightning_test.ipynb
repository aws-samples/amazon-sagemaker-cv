{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d919bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import functools\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.utils.comm import get_rank\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.utils.mlperf_logger import configure_logger\n",
    "from maskrcnn_benchmark.utils.mlperf_logger import log_start\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.solver import make_optimizer\n",
    "from maskrcnn_benchmark.solver import make_lr_scheduler\n",
    "from maskrcnn_benchmark.engine.trainer import do_train\n",
    "from scaleoutbridge import init_bridge, ScaleoutBridge as SBridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a450fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlperf_logging.mllog import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e587e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07ef085",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maskrcnn_benchmark.config import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b629422",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_logger(constants.MASKRCNN)\n",
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "distributed = num_gpus > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29a64ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='opts', nargs='...', const=None, default=None, type=None, choices=None, help='Modify config options using the command-line', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"PyTorch Object Detection Training\")\n",
    "parser.add_argument(\n",
    "        \"--config-file\",\n",
    "        default=\"\",\n",
    "        metavar=\"FILE\",\n",
    "        help=\"path to config file\",\n",
    "        type=str,\n",
    "    )\n",
    "parser.add_argument(\"--local_rank\", type=int, default=os.getenv('LOCAL_RANK', 0))\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    help=\"Modify config options using the command-line\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    ")\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df6d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(\"configs/e2e_mask_rcnn_R_50_FPN_1x_1_node_test.yaml\")\n",
    "# cfg.merge_from_list(args.opts)\n",
    "# cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348cf3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "args_distributed= num_gpus >1\n",
    "if args_distributed:\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    torch.distributed.init_process_group(\n",
    "        backend=\"nccl\", init_method=\"env://\"\n",
    "    )\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    rank = torch.distributed.get_rank()\n",
    "    # setting seeds - needs to be timed, so after RUN_START\n",
    "    if is_main_process():\n",
    "        master_seed = random.SystemRandom().randint(0, 2 ** 32 - 1)\n",
    "        seed_tensor = torch.tensor(master_seed, dtype=torch.float32, device=torch.device(\"cuda\"))\n",
    "    else:\n",
    "        seed_tensor = torch.tensor(0, dtype=torch.float32, device=torch.device(\"cuda\"))\n",
    "\n",
    "    torch.distributed.broadcast(seed_tensor, 0)\n",
    "    master_seed = int(seed_tensor.item())\n",
    "else:\n",
    "    world_size = 1\n",
    "    rank = 0\n",
    "    # random master seed, random.SystemRandom() uses /dev/urandom on Unix\n",
    "    master_seed = random.SystemRandom().randint(0, 2 ** 32 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec4434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedicated_evaluation_ranks = max(0,cfg.DEDICATED_EVALUATION_RANKS)\n",
    "num_training_ranks = world_size - dedicated_evaluation_ranks\n",
    "num_evaluation_ranks = world_size if dedicated_evaluation_ranks == 0 else dedicated_evaluation_ranks\n",
    "\n",
    "images_per_gpu_train = cfg.SOLVER.IMS_PER_BATCH // num_training_ranks\n",
    "images_per_gpu_test = cfg.TEST.IMS_PER_BATCH // num_evaluation_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "272fe5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = {}\n",
    "arguments[\"iteration\"] = 0\n",
    "arguments[\"nhwc\"] = cfg.NHWC\n",
    "arguments['ims_per_batch'] = cfg.SOLVER.IMS_PER_BATCH\n",
    "arguments[\"distributed\"] = distributed\n",
    "arguments[\"max_annotations_per_image\"] = cfg.DATALOADER.MAX_ANNOTATIONS_PER_IMAGE\n",
    "arguments[\"dedicated_evaluation_ranks\"] = dedicated_evaluation_ranks\n",
    "arguments[\"num_training_ranks\"] = num_training_ranks\n",
    "arguments[\"training_comm\"] = None if dedicated_evaluation_ranks == 0 else training_comm\n",
    "arguments[\"images_per_gpu_train\"] = images_per_gpu_train\n",
    "arguments[\"use_synthetic_input\"] = cfg.DATALOADER.USE_SYNTHETIC_INPUT\n",
    "assert not (cfg.DATALOADER.USE_SYNTHETIC_INPUT and cfg.DATALOADER.HYBRID), \"USE_SYNTHETIC_INPUT and HYBRID can't both be used together\"\n",
    "arguments[\"enable_nsys_profiling\"] = cfg.ENABLE_NSYS_PROFILING\n",
    "output_dir = cfg.OUTPUT_DIR\n",
    "\n",
    "# save_to_disk = get_rank() == 0\n",
    "# checkpointer = DetectronCheckpointer(\n",
    "#     cfg, model, optimizer, scheduler, output_dir, save_to_disk\n",
    "# )\n",
    "# arguments[\"save_checkpoints\"] = cfg.SAVE_CHECKPOINTS\n",
    "\n",
    "# extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT, cfg.NHWC)\n",
    "# arguments.update(extra_checkpoint_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "517d1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from rcnn_lightning import LightningGeneralizedRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce219888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824575, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824723, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824726, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824735, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824739, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824748, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824754, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824763, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824773, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 105, \"tensor\": \"RPNHead_conv\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824774, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 106, \"tensor\": \"RPNHead_cls\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926824774, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 107, \"tensor\": \"RPNHead_bbox\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827298, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py\", \"lineno\": 95, \"tensor\": \"ROI_BOX_FEATURE_EXTRACTOR_fc6\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827311, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py\", \"lineno\": 98, \"tensor\": \"ROI_BOX_FEATURE_EXTRACTOR_fc7\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827316, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\", \"lineno\": 50, \"tensor\": \"ROI_BOX_PREDICTOR_cls\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827319, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\", \"lineno\": 52, \"tensor\": \"ROI_BOX_PREDICTOR_bbox\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827330, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827340, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827349, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827357, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827362, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py\", \"lineno\": 54, \"tensor\": \"ROI_MASK_PREDICTOR_fcn5\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657926827363, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py\", \"lineno\": 55, \"tensor\": \"ROI_MASK_PREDICTOR_fcn_logits\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py:1095: UserWarning: _ConvTransposeMixin is a deprecated internal class. Please consider using public APIs.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = LightningGeneralizedRCNN(cfg, arguments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8afd0b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LightningGeneralizedRCNN(\n",
       "  (model): GeneralizedRCNN(\n",
       "    (graphable): Graphable(\n",
       "      (backbone): Sequential(\n",
       "        (body): ResNet(\n",
       "          (stem): StemWithFixedBatchNorm(\n",
       "            (_base_stem): _BaseStem(\n",
       "              (conv1): RecursiveScriptModule(original_name=Conv2d_NHWC)\n",
       "              (bn1): FrozenBatchNorm2d_NHWC()\n",
       "            )\n",
       "            (max_pool): MaxPool2d_NHWC(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "          (layer1): Sequential(\n",
       "            (0): FastBottleneckWithFixedBatchNorm(\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "              (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (1): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (2): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (layer2): Sequential(\n",
       "            (0): FastBottleneckWithFixedBatchNorm(\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "              (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (1): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (2): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (3): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (layer3): Sequential(\n",
       "            (0): FastBottleneckWithFixedBatchNorm(\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "              (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (1): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (2): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (3): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (4): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (5): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "          (layer4): Sequential(\n",
       "            (0): FastBottleneckWithFixedBatchNorm(\n",
       "              (downsample): Sequential(\n",
       "                (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                (1): FrozenBatchNorm2d()\n",
       "              )\n",
       "              (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (1): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (2): FastBottleneckWithFixedBatchNorm(\n",
       "              (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (relu): ReLU(inplace=True)\n",
       "              (bn1): FrozenBatchNorm2d()\n",
       "              (bn2): FrozenBatchNorm2d()\n",
       "              (bn3): FrozenBatchNorm2d()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (fpn): FPN(\n",
       "          (fpn_inner1): Conv2d_NHWC(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fpn_layer1): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (fpn_inner2): Conv2d_NHWC(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fpn_layer2): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (fpn_inner3): Conv2d_NHWC(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fpn_layer3): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (fpn_inner4): Conv2d_NHWC(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fpn_layer4): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (top_blocks): LastLevelMaxPool()\n",
       "        )\n",
       "      )\n",
       "      (anchor_generator): AnchorGenerator(\n",
       "        (cell_anchors): BufferList()\n",
       "      )\n",
       "      (head): RPNHead(\n",
       "        (conv): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (cls_logits): Conv2d_NHWC(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bbox_pred): Conv2d_NHWC(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (combined_rpn_roi): Combined_RPN_ROI(\n",
       "      (rpn): RPNModule(\n",
       "        (box_selector_train): RPNPostProcessor()\n",
       "        (box_selector_test): RPNPostProcessor()\n",
       "      )\n",
       "      (roi_heads): CombinedROIHeads(\n",
       "        (box): ROIBoxHead(\n",
       "          (feature_extractor): FPN2MLPFeatureExtractor(\n",
       "            (pooler): Pooler(\n",
       "              (poolers): ModuleList(\n",
       "                (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2)\n",
       "                (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2)\n",
       "                (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2)\n",
       "                (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2)\n",
       "              )\n",
       "              (flb_roi_align): FLBROIAlign(output_size=(7, 7), spatial_scale=(0.25, 0.125, 0.0625, 0.03125), sampling_ratio=2)\n",
       "            )\n",
       "            (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "            (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (predictor): FPNPredictor(\n",
       "            (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "            (bbox_pred): Linear(in_features=1024, out_features=324, bias=True)\n",
       "          )\n",
       "          (post_processor): PostProcessor()\n",
       "        )\n",
       "        (mask): ROIMaskHead(\n",
       "          (feature_extractor): MaskRCNNFPNFeatureExtractor(\n",
       "            (pooler): Pooler(\n",
       "              (poolers): ModuleList(\n",
       "                (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=2)\n",
       "                (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=2)\n",
       "                (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=2)\n",
       "                (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=2)\n",
       "              )\n",
       "              (flb_roi_align): FLBROIAlign(output_size=(14, 14), spatial_scale=(0.25, 0.125, 0.0625, 0.03125), sampling_ratio=2)\n",
       "            )\n",
       "            (roi_mask_head_fcn1): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (roi_mask_head_fcn2): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (roi_mask_head_fcn3): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (roi_mask_head_fcn4): Conv2d_NHWC(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          )\n",
       "          (predictor): MaskRCNNC4Predictor(\n",
       "            (mask_head_fcn5): ConvTranspose2d_NHWC(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "            (mask_head_fcn_logits): Conv2d_NHWC(256, 81, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (post_processor): MaskPostProcessor()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb24b071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7eac94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:92: PossibleUserWarning: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer=pl.Trainer(accelerator=\"gpu\", devices=1)\n",
    "# trainer=pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dc2b329",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "Unknown configuration for model optimizers. Output from `model.configure_optimizers()` should be one of:\n * `Optimizer`\n * [`Optimizer`]\n * ([`Optimizer`], [`_LRScheduler`])\n * {\"optimizer\": `Optimizer`, (optional) \"lr_scheduler\": `_LRScheduler`}\n * A list of the previously described dict format, with an optional \"frequency\" key (int)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:770\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;124;03mRuns the full optimization routine.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;124;03m    datamodule: An instance of :class:`~pytorch_lightning.core.datamodule.LightningDataModule`.\u001b[39;00m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 770\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:723\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 723\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:811\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    807\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_ckpt_path(\n\u001b[1;32m    809\u001b[0m     ckpt_path, model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    810\u001b[0m )\n\u001b[0;32m--> 811\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1217\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/single_device.py:72\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_to_device()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:139\u001b[0m, in \u001b[0;36mStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m\"\"\"Setup plugins for the trainer fit and creates optimizers.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;124;03m    trainer: the trainer instance\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39msetup(trainer)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_precision_plugin()\n\u001b[1;32m    141\u001b[0m optimizers_to_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/strategies/strategy.py:128\u001b[0m, in \u001b[0;36mStrategy.setup_optimizers\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (TrainerFn\u001b[38;5;241m.\u001b[39mFITTING, TrainerFn\u001b[38;5;241m.\u001b[39mTUNING):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler_configs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_frequencies \u001b[38;5;241m=\u001b[39m \u001b[43m_init_optimizers_and_lr_schedulers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:188\u001b[0m, in \u001b[0;36m_init_optimizers_and_lr_schedulers\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    183\u001b[0m     rank_zero_warn(\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[1;32m    186\u001b[0m     optim_conf \u001b[38;5;241m=\u001b[39m _MockOptimizer()\n\u001b[0;32m--> 188\u001b[0m optimizers, lr_schedulers, optimizer_frequencies, monitor \u001b[38;5;241m=\u001b[39m \u001b[43m_configure_optimizers\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptim_conf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m lr_scheduler_configs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    190\u001b[0m     _configure_schedulers_automatic_opt(lr_schedulers, monitor)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model\u001b[38;5;241m.\u001b[39mautomatic_optimization\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m _configure_schedulers_manual_opt(lr_schedulers)\n\u001b[1;32m    193\u001b[0m )\n\u001b[1;32m    194\u001b[0m _set_scheduler_opt_idx(optimizers, lr_scheduler_configs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py:251\u001b[0m, in \u001b[0;36m_configure_optimizers\u001b[0;34m(optim_conf)\u001b[0m\n\u001b[1;32m    248\u001b[0m     optimizers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(optim_conf)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# unknown configuration\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown configuration for model optimizers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Output from `model.configure_optimizers()` should be one of:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m * `Optimizer`\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m * [`Optimizer`]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m * ([`Optimizer`], [`_LRScheduler`])\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m * \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: `Optimizer`, (optional) \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: `_LRScheduler`}\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m * A list of the previously described dict format, with an optional \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrequency\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m key (int)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizers, lr_schedulers, optimizer_frequencies, monitor\n",
      "\u001b[0;31mMisconfigurationException\u001b[0m: Unknown configuration for model optimizers. Output from `model.configure_optimizers()` should be one of:\n * `Optimizer`\n * [`Optimizer`]\n * ([`Optimizer`], [`_LRScheduler`])\n * {\"optimizer\": `Optimizer`, (optional) \"lr_scheduler\": `_LRScheduler`}\n * A list of the previously described dict format, with an optional \"frequency\" key (int)"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aba6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[0].device"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
