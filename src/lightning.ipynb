{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94ec07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import functools\n",
    "from maskrcnn_benchmark.config import cfg\n",
    "from maskrcnn_benchmark.data import make_data_loader\n",
    "from maskrcnn_benchmark.utils.comm import get_rank\n",
    "from maskrcnn_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from maskrcnn_benchmark.utils.mlperf_logger import configure_logger\n",
    "from maskrcnn_benchmark.utils.mlperf_logger import log_start\n",
    "from maskrcnn_benchmark.modeling.detector import build_detection_model\n",
    "from maskrcnn_benchmark.solver import make_optimizer\n",
    "from maskrcnn_benchmark.solver import make_lr_scheduler\n",
    "from maskrcnn_benchmark.engine.trainer import do_train\n",
    "from scaleoutbridge import init_bridge, ScaleoutBridge as SBridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5db4e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlperf_logging.mllog import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd76f41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9569e8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "configure_logger(constants.MASKRCNN)\n",
    "num_gpus = int(os.environ[\"WORLD_SIZE\"]) if \"WORLD_SIZE\" in os.environ else 1\n",
    "distributed = num_gpus > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511b4a51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=[], dest='opts', nargs='...', const=None, default=None, type=None, choices=None, help='Modify config options using the command-line', metavar=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"PyTorch Object Detection Training\")\n",
    "parser.add_argument(\n",
    "        \"--config-file\",\n",
    "        default=\"\",\n",
    "        metavar=\"FILE\",\n",
    "        help=\"path to config file\",\n",
    "        type=str,\n",
    "    )\n",
    "parser.add_argument(\"--local_rank\", type=int, default=os.getenv('LOCAL_RANK', 0))\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    help=\"Modify config options using the command-line\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    ")\n",
    "\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11288ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_world():\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates number of devices in Sagemaker distributed cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get params of Sagemaker distributed cluster from predefined env variables\n",
    "    num_gpus = int(os.environ[\"SM_NUM_GPUS\"])\n",
    "    num_cpus = int(os.environ[\"SM_NUM_CPUS\"])\n",
    "    hosts = json.loads(os.environ[\"SM_HOSTS\"])\n",
    "    current_host = os.environ[\"SM_CURRENT_HOST\"]\n",
    "\n",
    "    # Define PyTorch training world\n",
    "    world = {}\n",
    "    world[\"number_of_processes\"] = num_gpus if num_gpus > 0 else num_cpus\n",
    "    world[\"number_of_machines\"] = len(hosts)\n",
    "    world[\"size\"] = world[\"number_of_processes\"] * world[\"number_of_machines\"]\n",
    "    world[\"machine_rank\"] = hosts.index(current_host)\n",
    "    world[\"master_addr\"] = hosts[0]\n",
    "    world[\"master_port\"] = \"55555\" # port is defined by Sagemaker\n",
    "\n",
    "    return world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9087f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SM_HPS\"]='{\"batch-size\": \"256\", \"learning-rate\": \"0.0001\",\"communicator\": \"pure_nccl\"}'\n",
    "os.environ[\"SM_NUM_GPUS\"]='1'\n",
    "os.environ[\"SM_NUM_CPUS\"]='32'\n",
    "os.environ[\"SM_HOSTS\"]='[\"algo-1\",\"algo-2\"]'\n",
    "os.environ[\"SM_CURRENT_HOST\"]=\"b51d59bfb99b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "896ee321",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"/workspace/data/all_data/\"\n",
    "train_script=\"/workspace/amazon-sagemaker-cv/src/aws_train_mlperf.py\"\n",
    "# unarchive_data(data_dir)\n",
    "# world = get_training_world()\n",
    "sm_args = json.loads(os.environ[\"SM_HPS\"])\n",
    "args = [f\"--{key} {value}\" for key, value in sm_args.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09252542",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8f073b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.merge_from_file(\"configs/e2e_mask_rcnn_R_50_FPN_1x_1_node_test.yaml\")\n",
    "# cfg.merge_from_list(args.opts)\n",
    "# cfg.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cff2edb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(800, 1344), (1344, 800)]\n"
     ]
    }
   ],
   "source": [
    "if cfg.DATALOADER.ALWAYS_PAD_TO_MAX or cfg.USE_CUDA_GRAPH:\n",
    "    min_size = cfg.INPUT.MIN_SIZE_TRAIN[0] if isinstance(cfg.INPUT.MIN_SIZE_TRAIN, tuple) else cfg.INPUT.MIN_SIZE_TRAIN\n",
    "    max_size = cfg.INPUT.MAX_SIZE_TRAIN[0] if isinstance(cfg.INPUT.MAX_SIZE_TRAIN, tuple) else cfg.INPUT.MAX_SIZE_TRAIN\n",
    "    divisibility = max(1, cfg.DATALOADER.SIZE_DIVISIBILITY)\n",
    "    shapes_per_orientation = cfg.CUDA_GRAPH_NUM_SHAPES_PER_ORIENTATION\n",
    "\n",
    "    min_size = ((min_size + divisibility - 1) // divisibility) * divisibility\n",
    "    max_size = ((max_size + divisibility - 1) // divisibility) * divisibility\n",
    "    size_range = (max_size - min_size) // divisibility\n",
    "\n",
    "    shapes = []\n",
    "    for i in range(0,shapes_per_orientation):\n",
    "        size = min_size + ((i+1) * size_range // shapes_per_orientation) * divisibility\n",
    "        shapes.append( (min_size, size) )\n",
    "        shapes.append( (size, min_size) )\n",
    "    print(shapes)\n",
    "else:\n",
    "    shapes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "897ba394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=13.65s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "master_seed = random.SystemRandom().randint(0, 2 ** 32 - 1)\n",
    "random_number_generator = random.Random(master_seed)\n",
    "data_loader, iters_per_epoch = make_data_loader(\n",
    "            cfg,\n",
    "            is_train=True,\n",
    "            is_distributed=distributed,\n",
    "            start_iter=0,\n",
    "            random_number_generator=random_number_generator,\n",
    "            seed=master_seed,\n",
    "            shapes=shapes,\n",
    "            hybrid_dataloader=None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f7bd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlperf_log_epoch_start(iteration, iters_per_epoch):\n",
    "    # First iteration:\n",
    "    #     Note we've started training & tag first epoch start\n",
    "    if iteration == 0:\n",
    "        log_start(key=constants.BLOCK_START, metadata={\"first_epoch_num\":1, \"epoch_count\":1})\n",
    "        log_start(key=constants.EPOCH_START, metadata={\"epoch_num\":1})\n",
    "        return\n",
    "    if iteration % iters_per_epoch == 0:\n",
    "        epoch = iteration // iters_per_epoch + 1\n",
    "        log_start(key=constants.BLOCK_START, metadata={\"first_epoch_num\": epoch, \"epoch_count\": 1})\n",
    "        log_start(key=constants.EPOCH_START, metadata={\"epoch_num\": epoch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e178e6b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664530929, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531069, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531075, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531093, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531100, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531110, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531118, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531126, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531137, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 105, \"tensor\": \"RPNHead_conv\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531139, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 106, \"tensor\": \"RPNHead_cls\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531139, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 107, \"tensor\": \"RPNHead_bbox\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531327, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py\", \"lineno\": 95, \"tensor\": \"ROI_BOX_FEATURE_EXTRACTOR_fc6\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531342, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py\", \"lineno\": 98, \"tensor\": \"ROI_BOX_FEATURE_EXTRACTOR_fc7\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531347, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\", \"lineno\": 50, \"tensor\": \"ROI_BOX_PREDICTOR_cls\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531350, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\", \"lineno\": 52, \"tensor\": \"ROI_BOX_PREDICTOR_bbox\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531360, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531369, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531378, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531387, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531392, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py\", \"lineno\": 54, \"tensor\": \"ROI_MASK_PREDICTOR_fcn5\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664531393, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py\", \"lineno\": 55, \"tensor\": \"ROI_MASK_PREDICTOR_fcn_logits\"}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GeneralizedRCNN(\n",
       "  (graphable): Graphable(\n",
       "    (backbone): Sequential(\n",
       "      (body): ResNet(\n",
       "        (stem): StemWithFixedBatchNorm(\n",
       "          (_base_stem): _BaseStem(\n",
       "            (conv1): RecursiveScriptModule(original_name=Conv2d)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (max_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        )\n",
       "        (layer1): Sequential(\n",
       "          (0): FastBottleneckWithFixedBatchNorm(\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (1): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (2): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (0): FastBottleneckWithFixedBatchNorm(\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (1): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (2): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (3): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (layer3): Sequential(\n",
       "          (0): FastBottleneckWithFixedBatchNorm(\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (1): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (2): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (3): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (4): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (5): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "        (layer4): Sequential(\n",
       "          (0): FastBottleneckWithFixedBatchNorm(\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): FrozenBatchNorm2d()\n",
       "            )\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (1): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "          (2): FastBottleneckWithFixedBatchNorm(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (bn1): FrozenBatchNorm2d()\n",
       "            (bn2): FrozenBatchNorm2d()\n",
       "            (bn3): FrozenBatchNorm2d()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (fpn): FPN(\n",
       "        (fpn_inner1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (fpn_inner2): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (fpn_inner3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (fpn_inner4): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (fpn_layer4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (top_blocks): LastLevelMaxPool()\n",
       "      )\n",
       "    )\n",
       "    (anchor_generator): AnchorGenerator(\n",
       "      (cell_anchors): BufferList()\n",
       "    )\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (combined_rpn_roi): Combined_RPN_ROI(\n",
       "    (rpn): RPNModule(\n",
       "      (box_selector_train): RPNPostProcessor()\n",
       "      (box_selector_test): RPNPostProcessor()\n",
       "    )\n",
       "    (roi_heads): CombinedROIHeads(\n",
       "      (box): ROIBoxHead(\n",
       "        (feature_extractor): FPN2MLPFeatureExtractor(\n",
       "          (pooler): Pooler(\n",
       "            (poolers): ModuleList(\n",
       "              (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=2)\n",
       "              (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=2)\n",
       "              (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=2)\n",
       "              (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=2)\n",
       "            )\n",
       "            (flb_roi_align): FLBROIAlign(output_size=(7, 7), spatial_scale=(0.25, 0.125, 0.0625, 0.03125), sampling_ratio=2)\n",
       "          )\n",
       "          (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "          (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (predictor): FPNPredictor(\n",
       "          (cls_score): Linear(in_features=1024, out_features=81, bias=True)\n",
       "          (bbox_pred): Linear(in_features=1024, out_features=324, bias=True)\n",
       "        )\n",
       "        (post_processor): PostProcessor()\n",
       "      )\n",
       "      (mask): ROIMaskHead(\n",
       "        (feature_extractor): MaskRCNNFPNFeatureExtractor(\n",
       "          (pooler): Pooler(\n",
       "            (poolers): ModuleList(\n",
       "              (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=2)\n",
       "              (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=2)\n",
       "              (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=2)\n",
       "              (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=2)\n",
       "            )\n",
       "            (flb_roi_align): FLBROIAlign(output_size=(14, 14), spatial_scale=(0.25, 0.125, 0.0625, 0.03125), sampling_ratio=2)\n",
       "          )\n",
       "          (roi_mask_head_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (roi_mask_head_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (roi_mask_head_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (roi_mask_head_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (predictor): MaskRCNNC4Predictor(\n",
       "          (mask_head_fcn5): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "          (mask_head_fcn_logits): Conv2d(256, 81, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (post_processor): MaskPostProcessor()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_detection_model(cfg)\n",
    "device = torch.device(cfg.MODEL.DEVICE)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "775f5ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 1\n",
    "dedicated_evaluation_ranks = max(0,cfg.DEDICATED_EVALUATION_RANKS)\n",
    "num_training_ranks = world_size - dedicated_evaluation_ranks\n",
    "images_per_gpu_train = cfg.SOLVER.IMS_PER_BATCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc07131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_per_gpu_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1515951c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "optimizer = make_optimizer(cfg, model)\n",
    "scheduler = make_lr_scheduler(cfg, optimizer)\n",
    "checkpoint_period = cfg.SOLVER.CHECKPOINT_PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f1854a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "arguments = {}\n",
    "arguments[\"iteration\"] = 0\n",
    "arguments[\"nhwc\"] = cfg.NHWC\n",
    "arguments['ims_per_batch'] = cfg.SOLVER.IMS_PER_BATCH\n",
    "arguments[\"distributed\"] = distributed\n",
    "arguments[\"max_annotations_per_image\"] = cfg.DATALOADER.MAX_ANNOTATIONS_PER_IMAGE\n",
    "arguments[\"dedicated_evaluation_ranks\"] = dedicated_evaluation_ranks\n",
    "arguments[\"num_training_ranks\"] = num_training_ranks\n",
    "arguments[\"training_comm\"] = None if dedicated_evaluation_ranks == 0 else training_comm\n",
    "arguments[\"images_per_gpu_train\"] = images_per_gpu_train\n",
    "arguments[\"use_synthetic_input\"] = cfg.DATALOADER.USE_SYNTHETIC_INPUT\n",
    "assert not (cfg.DATALOADER.USE_SYNTHETIC_INPUT and cfg.DATALOADER.HYBRID), \"USE_SYNTHETIC_INPUT and HYBRID can't both be used together\"\n",
    "arguments[\"enable_nsys_profiling\"] = cfg.ENABLE_NSYS_PROFILING\n",
    "output_dir = cfg.OUTPUT_DIR\n",
    "\n",
    "save_to_disk = get_rank() == 0\n",
    "checkpointer = DetectronCheckpointer(\n",
    "    cfg, model, optimizer, scheduler, output_dir, save_to_disk\n",
    ")\n",
    "arguments[\"save_checkpoints\"] = cfg.SAVE_CHECKPOINTS\n",
    "\n",
    "extra_checkpoint_data = checkpointer.load(cfg.MODEL.WEIGHT, cfg.NHWC)\n",
    "arguments.update(extra_checkpoint_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a83c448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_iter_callback_fn = None\n",
    "final_callback_fn=None\n",
    "rank=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50c7dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664537994, \"event_type\": \"INTERVAL_START\", \"key\": \"block_start\", \"value\": null, \"metadata\": {\"file\": \"/tmp/ipykernel_18863/677983664.py\", \"lineno\": 5, \"first_epoch_num\": 1, \"epoch_count\": 1}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657664538002, \"event_type\": \"INTERVAL_START\", \"key\": \"epoch_start\", \"value\": null, \"metadata\": {\"file\": \"/tmp/ipykernel_18863/677983664.py\", \"lineno\": 6, \"epoch_num\": 1}}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 361, in forward\n    @torch.jit.script_method\n    def forward(self, x):\n        x = self.conv1(x)\n            ~~~~~~~~~~ <--- HERE\n        x = self.bn1(x)\n        x = F.relu(x)\nRuntimeError: AttributeError: 'RecursiveScriptModule' object has no attribute '_conv_forward'\n\nAt:\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1186): __getattr__\n  /opt/conda/lib/python3.8/site-packages/torch/jit/_script.py(481): __getattr__\n  /opt/conda/lib/python3.8/site-packages/torch/jit/_script.py(764): __getattr__\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py(447): forward\n  /workspace/maskrcnn/maskrcnn_benchmark/layers/misc.py(34): forward\n  /opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py(899): lazy_binding_method\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py(380): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py(161): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py(139): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py(30): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py(393): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/engine/trainer.py(382): do_train\n  /tmp/ipykernel_18863/741175699.py(1): <cell line: 1>\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3398): run_code\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3338): run_ast_nodes\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3135): run_cell_async\n  /opt/conda/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2936): _run_cell\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2881): run_cell\n  /opt/conda/lib/python3.8/site-packages/ipykernel/zmqshell.py(528): run_cell\n  /opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py(383): do_execute\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(724): execute_request\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(400): dispatch_shell\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(493): process_one\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(504): dispatch_queue\n  /opt/conda/lib/python3.8/asyncio/events.py(81): _run\n  /opt/conda/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /opt/conda/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /opt/conda/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelapp.py(712): start\n  /opt/conda/lib/python3.8/site-packages/traitlets/config/application.py(846): launch_instance\n  /opt/conda/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n  /opt/conda/lib/python3.8/runpy.py(87): _run_code\n  /opt/conda/lib/python3.8/runpy.py(194): _run_module_as_main\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m success \u001b[38;5;241m=\u001b[39m \u001b[43mdo_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43marguments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDISABLE_REDUCED_LOGGING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDISABLE_LOSS_LOGGING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mper_iter_start_callback_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunctools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlperf_log_epoch_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miters_per_epoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mper_iter_end_callback_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mper_iter_callback_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfinal_callback_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_callback_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrank\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/maskrcnn/maskrcnn_benchmark/engine/trainer.py:382\u001b[0m, in \u001b[0;36mdo_train\u001b[0;34m(model, data_loader, optimizer, scheduler, checkpointer, device, checkpoint_period, arguments, disable_allreduce_for_logging, disable_loss_logging, per_iter_start_callback_fn, per_iter_end_callback_fn, final_callback_fn, rank)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    380\u001b[0m         torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[0;32m--> 382\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[1;32m    386\u001b[0m sbridge\u001b[38;5;241m.\u001b[39mstop_start_prof(SBridge\u001b[38;5;241m.\u001b[39mFWD_TIME, SBridge\u001b[38;5;241m.\u001b[39mBWD_TIME)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/maskrcnn/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py:393\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdali \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnhwc:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;66;03m# dali pipeline outputs nhwc images\u001b[39;00m\n\u001b[1;32m    392\u001b[0m         images\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m nhwc_to_nchw_transform(images\u001b[38;5;241m.\u001b[39mtensors)\n\u001b[0;32m--> 393\u001b[0m flat_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraphable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_sizes_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m features, objectness, rpn_box_regression, anchor_boxes, anchor_visibility \u001b[38;5;241m=\u001b[39m flat_res[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m5\u001b[39m], \u001b[38;5;28mlist\u001b[39m(flat_res[\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m10\u001b[39m]), \u001b[38;5;28mlist\u001b[39m(flat_res[\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m15\u001b[39m]), flat_res[\u001b[38;5;241m15\u001b[39m], flat_res[\u001b[38;5;241m16\u001b[39m]\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcombined_rpn_roi(images, anchor_boxes, anchor_visibility, objectness, rpn_box_regression, targets, features)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/maskrcnn/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py:30\u001b[0m, in \u001b[0;36mGraphable.forward\u001b[0;34m(self, images_tensor, image_sizes_tensor)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images_tensor, image_sizes_tensor):\n\u001b[1;32m     29\u001b[0m     current_stream \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mcurrent_stream()\n\u001b[0;32m---> 30\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream1\u001b[38;5;241m.\u001b[39mwait_stream(current_stream)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mstream(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream1):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py:161\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    160\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 161\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stage_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstages:\n\u001b[1;32m    163\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, stage_name)(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py:380\u001b[0m, in \u001b[0;36mBaseStem.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 380\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_base_stem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pool(x)\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1111\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py\", line 361, in forward\n    @torch.jit.script_method\n    def forward(self, x):\n        x = self.conv1(x)\n            ~~~~~~~~~~ <--- HERE\n        x = self.bn1(x)\n        x = F.relu(x)\nRuntimeError: AttributeError: 'RecursiveScriptModule' object has no attribute '_conv_forward'\n\nAt:\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1186): __getattr__\n  /opt/conda/lib/python3.8/site-packages/torch/jit/_script.py(481): __getattr__\n  /opt/conda/lib/python3.8/site-packages/torch/jit/_script.py(764): __getattr__\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/conv.py(447): forward\n  /workspace/maskrcnn/maskrcnn_benchmark/layers/misc.py(34): forward\n  /opt/conda/lib/python3.8/site-packages/torch/jit/_recursive.py(899): lazy_binding_method\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py(380): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/resnet.py(161): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py(139): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py(30): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/modeling/detector/generalized_rcnn.py(393): forward\n  /opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py(1111): _call_impl\n  /workspace/maskrcnn/maskrcnn_benchmark/engine/trainer.py(382): do_train\n  /tmp/ipykernel_18863/741175699.py(1): <cell line: 1>\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3398): run_code\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3338): run_ast_nodes\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(3135): run_cell_async\n  /opt/conda/lib/python3.8/site-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2936): _run_cell\n  /opt/conda/lib/python3.8/site-packages/IPython/core/interactiveshell.py(2881): run_cell\n  /opt/conda/lib/python3.8/site-packages/ipykernel/zmqshell.py(528): run_cell\n  /opt/conda/lib/python3.8/site-packages/ipykernel/ipkernel.py(383): do_execute\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(724): execute_request\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(400): dispatch_shell\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(493): process_one\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelbase.py(504): dispatch_queue\n  /opt/conda/lib/python3.8/asyncio/events.py(81): _run\n  /opt/conda/lib/python3.8/asyncio/base_events.py(1859): _run_once\n  /opt/conda/lib/python3.8/asyncio/base_events.py(570): run_forever\n  /opt/conda/lib/python3.8/site-packages/tornado/platform/asyncio.py(199): start\n  /opt/conda/lib/python3.8/site-packages/ipykernel/kernelapp.py(712): start\n  /opt/conda/lib/python3.8/site-packages/traitlets/config/application.py(846): launch_instance\n  /opt/conda/lib/python3.8/site-packages/ipykernel_launcher.py(17): <module>\n  /opt/conda/lib/python3.8/runpy.py(87): _run_code\n  /opt/conda/lib/python3.8/runpy.py(194): _run_module_as_main\n\n"
     ]
    }
   ],
   "source": [
    "success = do_train(\n",
    "            model,\n",
    "            data_loader,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            checkpointer,\n",
    "            device,\n",
    "            checkpoint_period,\n",
    "            arguments,\n",
    "            cfg.DISABLE_REDUCED_LOGGING,\n",
    "            cfg.DISABLE_LOSS_LOGGING,\n",
    "            per_iter_start_callback_fn=functools.partial(mlperf_log_epoch_start, iters_per_epoch=iters_per_epoch),\n",
    "            per_iter_end_callback_fn=per_iter_callback_fn,\n",
    "            final_callback_fn=final_callback_fn,\n",
    "            rank=rank\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "376204e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_iter = arguments[\"iteration\"]\n",
    "prefetcher = Prefetcher(data_loader, device, arguments[\"max_annotations_per_image\"])\n",
    "overflow_buf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d202b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe231278",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SM_HPS\"] = '{\"batch-size\": \"256\", \"learning-rate\": \"0.0001\",\"communicator\": \"pure_nccl\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bbe8e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_args = json.loads(os.environ[\"SM_HPS\"])\n",
    "args = [f\"--{key} {value}\" for key, value in sm_args.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e830c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--config-file FILE]\n",
      "                             [--local_rank LOCAL_RANK]\n",
      "                             ...\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"PyTorch Object Detection Training\")\n",
    "parser.add_argument(\n",
    "    \"--config-file\",\n",
    "    default=\"\",\n",
    "    metavar=\"FILE\",\n",
    "    help=\"path to config file\",\n",
    "    type=str,\n",
    ")\n",
    "parser.add_argument(\"--local_rank\", type=int, default=os.getenv('LOCAL_RANK', 0))\n",
    "parser.add_argument(\n",
    "    \"opts\",\n",
    "    help=\"Modify config options using the command-line\",\n",
    "    default=None,\n",
    "    nargs=argparse.REMAINDER,\n",
    ")\n",
    "\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660cdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from rcnn_lightning import LightningGeneralizedRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbfe9456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      "Error: Apex bottleneck only support nhwc\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038298, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038416, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038418, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038427, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038431, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038439, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038447, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 56, \"tensor\": \"FPN_inner_block4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038455, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/backbone/fpn.py\", \"lineno\": 59, \"tensor\": \"FPN_layer_block4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038473, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 105, \"tensor\": \"RPNHead_conv\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038474, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 106, \"tensor\": \"RPNHead_cls\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820038475, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/rpn/rpn.py\", \"lineno\": 107, \"tensor\": \"RPNHead_bbox\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043012, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py\", \"lineno\": 95, \"tensor\": \"ROI_BOX_FEATURE_EXTRACTOR_fc6\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043026, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_feature_extractors.py\", \"lineno\": 98, \"tensor\": \"ROI_BOX_FEATURE_EXTRACTOR_fc7\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043031, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\", \"lineno\": 50, \"tensor\": \"ROI_BOX_PREDICTOR_cls\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043034, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/box_head/roi_box_predictors.py\", \"lineno\": 52, \"tensor\": \"ROI_BOX_PREDICTOR_bbox\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043043, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn1\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043052, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn2\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043060, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn3\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043069, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_feature_extractors.py\", \"lineno\": 64, \"tensor\": \"ROI_MASK_FEATURE_EXTRACTOR_fcn4\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043073, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py\", \"lineno\": 54, \"tensor\": \"ROI_MASK_PREDICTOR_fcn5\"}}\n",
      ":::MLLOG {\"namespace\": \"\", \"time_ms\": 1657820043074, \"event_type\": \"POINT_IN_TIME\", \"key\": \"weights_initialization\", \"value\": null, \"metadata\": {\"file\": \"/workspace/maskrcnn/maskrcnn_benchmark/modeling/roi_heads/mask_head/roi_mask_predictors.py\", \"lineno\": 55, \"tensor\": \"ROI_MASK_PREDICTOR_fcn_logits\"}}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "cannot assign module before Module.__init__() call",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mLightningGeneralizedRCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m=\u001b[39mpl\u001b[38;5;241m.\u001b[39mTrainer()\n",
      "File \u001b[0;32m/workspace/amazon-sagemaker-cv/src/rcnn_lightning.py:10\u001b[0m, in \u001b[0;36mLightningGeneralizedRCNN.__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, cfg):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m build_detection_model(cfg)\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg \u001b[38;5;241m=\u001b[39m cfg\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fp16 \u001b[38;5;241m=\u001b[39m (sfg\u001b[38;5;241m.\u001b[39mDTYPE \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat16\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1215\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Module):\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m modules \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot assign module before Module.__init__() call\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1217\u001b[0m     remove_from(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_non_persistent_buffers_set)\n\u001b[1;32m   1218\u001b[0m     modules[name] \u001b[38;5;241m=\u001b[39m value\n",
      "\u001b[0;31mAttributeError\u001b[0m: cannot assign module before Module.__init__() call"
     ]
    }
   ],
   "source": [
    "model = LightningGeneralizedRCNN(cfg)\n",
    "trainer=pl.Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7badbd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LightningGeneralizedRCNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(\u001b[43mLightningGeneralizedRCNN\u001b[49m())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LightningGeneralizedRCNN' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556f621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
